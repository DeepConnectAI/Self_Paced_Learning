{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Thank you all so very much.', 'Thank you to the Academy.', 'Thank you to all of you in this room.']\n"
     ]
    }
   ],
   "source": [
    "#Library for NLP\n",
    "\n",
    "import nltk\n",
    "#nltk.download()\n",
    "\n",
    "paragraph = \"\"\"Thank you all so very much. Thank you to the Academy. \n",
    "               Thank you to all of you in this room. I have to congratulate \n",
    "               the other incredible nominees this year. The Revenant was \n",
    "               the product of the tireless efforts of an unbelievable cast\n",
    "               and crew. First off, to my brother in this endeavor, Mr. Tom \n",
    "               Hardy. Tom, your talent on screen can only be surpassed by \n",
    "               your friendship off screen … thank you for creating a t\n",
    "               ranscendent cinematic experience. Thank you to everybody at \n",
    "               Fox and New Regency … my entire team. I have to thank \n",
    "               everyone from the very onset of my career … To my parents; \n",
    "               none of this would be possible without you. And to my \n",
    "               friends, I love you dearly; you know who you are. And lastly,\n",
    "               I just want to say this: Making The Revenant was about\n",
    "               man's relationship to the natural world. A world that we\n",
    "               collectively felt in 2015 as the hottest year in recorded\n",
    "               history. Our production needed to move to the southern\n",
    "               tip of this planet just to be able to find snow. Climate\n",
    "               change is real, it is happening right now. It is the most\n",
    "               urgent threat facing our entire species, and we need to work\n",
    "               collectively together and stop procrastinating. We need to\n",
    "               support leaders around the world who do not speak for the \n",
    "               big polluters, but who speak for all of humanity, for the\n",
    "               indigenous people of the world, for the billions and \n",
    "               billions of underprivileged people out there who would be\n",
    "               most affected by this. For our children’s children, and \n",
    "               for those people out there whose voices have been drowned\n",
    "               out by the politics of greed. I thank you all for this \n",
    "               amazing award tonight. Let us not take this planet for \n",
    "               granted. I do not take tonight for granted. Thank you so very much.\"\"\"\n",
    "\n",
    "# Give all sentences in a paragraph               \n",
    "sentences = nltk.sent_tokenize(paragraph) \n",
    "#print 3 sentences\n",
    "print(sentences[:3])\n",
    "        \n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Thank', 'you', 'all', 'so', 'very', 'much', '.', 'Thank', 'you', 'to', 'the', 'Academy', '.', 'Thank', 'you', 'to', 'all', 'of', 'you', 'in', 'this', 'room', '.', 'I', 'have', 'to', 'congratulate', 'the', 'other', 'incredible', 'nominees', 'this', 'year', '.', 'The', 'Revenant', 'was', 'the', 'product', 'of', 'the', 'tireless', 'efforts', 'of', 'an', 'unbelievable', 'cast', 'and', 'crew', '.', 'First', 'off', ',', 'to', 'my', 'brother', 'in', 'this', 'endeavor', ',', 'Mr.', 'Tom', 'Hardy', '.', 'Tom', ',', 'your', 'talent', 'on', 'screen', 'can', 'only', 'be', 'surpassed', 'by', 'your', 'friendship', 'off', 'screen', '…', 'thank', 'you', 'for', 'creating', 'a', 't', 'ranscendent', 'cinematic', 'experience', '.', 'Thank', 'you', 'to', 'everybody', 'at', 'Fox', 'and', 'New', 'Regency', '…', 'my', 'entire', 'team', '.', 'I', 'have', 'to', 'thank', 'everyone', 'from', 'the', 'very', 'onset', 'of', 'my', 'career', '…', 'To', 'my', 'parents', ';', 'none', 'of', 'this', 'would', 'be', 'possible', 'without', 'you', '.', 'And', 'to', 'my', 'friends', ',', 'I', 'love', 'you', 'dearly', ';', 'you', 'know', 'who', 'you', 'are', '.', 'And', 'lastly', ',', 'I', 'just', 'want', 'to', 'say', 'this', ':', 'Making', 'The', 'Revenant', 'was', 'about', 'man', \"'s\", 'relationship', 'to', 'the', 'natural', 'world', '.', 'A', 'world', 'that', 'we', 'collectively', 'felt', 'in', '2015', 'as', 'the', 'hottest', 'year', 'in', 'recorded', 'history', '.', 'Our', 'production', 'needed', 'to', 'move', 'to', 'the', 'southern', 'tip', 'of', 'this', 'planet', 'just', 'to', 'be', 'able', 'to', 'find', 'snow', '.', 'Climate', 'change', 'is', 'real', ',', 'it', 'is', 'happening', 'right', 'now', '.', 'It', 'is', 'the', 'most', 'urgent', 'threat', 'facing', 'our', 'entire', 'species', ',', 'and', 'we', 'need', 'to', 'work', 'collectively', 'together', 'and', 'stop', 'procrastinating', '.', 'We', 'need', 'to', 'support', 'leaders', 'around', 'the', 'world', 'who', 'do', 'not', 'speak', 'for', 'the', 'big', 'polluters', ',', 'but', 'who', 'speak', 'for', 'all', 'of', 'humanity', ',', 'for', 'the', 'indigenous', 'people', 'of', 'the', 'world', ',', 'for', 'the', 'billions', 'and', 'billions', 'of', 'underprivileged', 'people', 'out', 'there', 'who', 'would', 'be', 'most', 'affected', 'by', 'this', '.', 'For', 'our', 'children', '’', 's', 'children', ',', 'and', 'for', 'those', 'people', 'out', 'there', 'whose', 'voices', 'have', 'been', 'drowned', 'out', 'by', 'the', 'politics', 'of', 'greed', '.', 'I', 'thank', 'you', 'all', 'for', 'this', 'amazing', 'award', 'tonight', '.', 'Let', 'us', 'not', 'take', 'this', 'planet', 'for', 'granted', '.', 'I', 'do', 'not', 'take', 'tonight', 'for', 'granted', '.', 'Thank', 'you', 'so', 'very', 'much', '.']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Gives all words in paragraph\n",
    "words  = nltk.word_tokenize(paragraph) \n",
    "print(words) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
